{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Classification\n",
    "\n",
    "Dans une première partie, nous allons nous intéresser à la classification. On va importer des datasets de sklearn et entraîner notre modèle de XGBOOST sur de la classification binaire et multi-classes et le comparer avec deux modèles d'arbres de décision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.1 Importer les datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((455, 30), (114, 30))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris, fetch_covtype, load_breast_cancer  \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Charger un jeu de données Iris pour classification\n",
    "iris = load_iris()\n",
    "X, Y = iris.data, iris.target\n",
    "\n",
    "covertype = fetch_covtype()\n",
    "X, Y = covertype.data, covertype.target\n",
    "Y = Y - 1   # car les classes dans cette dataset commencent de 1 et pas de 0 \n",
    "\n",
    "cancer = load_breast_cancer()   # Pour la classification binaire\n",
    "X, Y = cancer.data, cancer.target\n",
    "\n",
    "# Diviser les données en ensembles d'entraînement et de test\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.2 Entraîner deux modèles d'arbres de décision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fin\n"
     ]
    }
   ],
   "source": [
    "from   sklearn.tree    import DecisionTreeClassifier\n",
    "from   sklearn.metrics import accuracy_score, f1_score\n",
    "from   sklearn         import tree\n",
    "import timeit\n",
    "\n",
    "Xchoix_train = X_train\n",
    "Ychoix_train = Y_train\n",
    "Xchoix_test  = X_test\n",
    "Ychoix_test  = Y_test\n",
    "# fnames       = iris.columns\n",
    "\n",
    "\n",
    "gini_stats          = []\n",
    "entropy_stats       = []\n",
    "gini_classifieur    = DecisionTreeClassifier(criterion='gini'   , random_state=42)\n",
    "entropy_classifieur = DecisionTreeClassifier(criterion='entropy', random_state=42)\n",
    "\n",
    "# ============ GINI ====================\n",
    "# ............ Entraînement ............\n",
    "temps_debut = timeit.default_timer()\n",
    "gini_classifieur.fit(Xchoix_train, Ychoix_train)\n",
    "gini_stats.append(timeit.default_timer() - temps_debut)\n",
    "# ..... Evaluation entrainement ........\n",
    "Ychoix_pred = gini_classifieur.predict(Xchoix_train)\n",
    "gini_stats.append(accuracy_score(Ychoix_train, Ychoix_pred))\n",
    "gini_stats.append(f1_score(Ychoix_train, Ychoix_pred, average='micro'))\n",
    "# ................ Test ................\n",
    "temps_debut = timeit.default_timer()\n",
    "Ychoix_pred = gini_classifieur.predict(Xchoix_test)\n",
    "gini_stats.append(timeit.default_timer() - temps_debut)\n",
    "# ........... Evaluation test ...........\n",
    "gini_stats.append(accuracy_score(Ychoix_test, Ychoix_pred))\n",
    "gini_stats.append(f1_score(Ychoix_test, Ychoix_pred, average='micro'))\n",
    "\n",
    "# =========== Entropy ==================\n",
    "# ............ Entraînement ............\n",
    "temps_debut = timeit.default_timer()\n",
    "entropy_classifieur.fit(Xchoix_train, Ychoix_train)\n",
    "entropy_stats.append(timeit.default_timer() - temps_debut)\n",
    "# ..... Evaluation entrainement ........\n",
    "Ychoix_pred = entropy_classifieur.predict(Xchoix_train)\n",
    "entropy_stats.append(accuracy_score(Ychoix_train, Ychoix_pred))\n",
    "entropy_stats.append(f1_score(Ychoix_train, Ychoix_pred, average='micro'))\n",
    "# ................ Test ................\n",
    "temps_debut = timeit.default_timer()\n",
    "Ychoix_pred = entropy_classifieur.predict(Xchoix_test)\n",
    "entropy_stats.append(timeit.default_timer() - temps_debut)\n",
    "# ........... Evaluation test ...........\n",
    "entropy_stats.append(accuracy_score(Ychoix_test, Ychoix_pred))\n",
    "entropy_stats.append(f1_score(Ychoix_test, Ychoix_pred, average='micro'))\n",
    "\n",
    "print('Fin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.3 Entraîner un modèle XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Définir les paramètres du modèle\n",
    "# params = {\n",
    "#     'objective': 'multi:softmax',  # Fonction objective pour la classification multi-classe\n",
    "#     'num_class': 7,  # Nombre de classes dans le jeu de données \n",
    "#     'max_depth': 4  # Profondeur maximale de l'arbre\n",
    "# }\n",
    "# params = {\n",
    "#     'objective': 'binary:logistic',  # Fonction objective pour la classification binaire\n",
    "#     'num_class': 2, \n",
    "#     'max_depth': 3\n",
    "# }\n",
    "XGBOOST_stats = []\n",
    "\n",
    "# Créer le modèle de classification (avec les paramètres par défaut)\n",
    "clf = xgb.XGBClassifier()\n",
    "\n",
    "\n",
    "# ================= Entraînement =====================\n",
    "temps_debut = timeit.default_timer()\n",
    "# Entraîner le modèle\n",
    "clf.fit(X_train, Y_train)\n",
    "XGBOOST_stats.append(timeit.default_timer() - temps_debut)\n",
    "Y_pred = clf.predict(X_train)\n",
    "XGBOOST_stats.append(accuracy_score(Y_train, Y_pred))\n",
    "XGBOOST_stats.append(f1_score(Y_train, Y_pred, average='micro'))\n",
    "\n",
    "# ===================== Test ========================\n",
    "temps_debut = timeit.default_timer()\n",
    "# Faire des prédictions sur l'ensemble de test\n",
    "Y_pred = clf.predict(X_test)\n",
    "XGBOOST_stats.append(timeit.default_timer() - temps_debut)\n",
    "XGBOOST_stats.append(accuracy_score(Y_test, Y_pred))\n",
    "XGBOOST_stats.append(f1_score(Y_test, Y_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Criteres</th>\n",
       "      <th>Entropie</th>\n",
       "      <th>Gini</th>\n",
       "      <th>XGBOOST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Temps Entrainement</td>\n",
       "      <td>0.021726</td>\n",
       "      <td>0.026059</td>\n",
       "      <td>0.108158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Accuracy Entrainement</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F1 Entrainement</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Temps Test</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>0.000451</td>\n",
       "      <td>0.000718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Accuracy Test</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.956140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>F1 Test</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.956140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Criteres  Entropie      Gini   XGBOOST\n",
       "0     Temps Entrainement  0.021726  0.026059  0.108158\n",
       "1  Accuracy Entrainement  1.000000  1.000000  1.000000\n",
       "2        F1 Entrainement  1.000000  1.000000  1.000000\n",
       "3             Temps Test  0.000228  0.000451  0.000718\n",
       "4          Accuracy Test  0.947368  0.947368  0.956140\n",
       "5                F1 Test  0.947368  0.947368  0.956140"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\n",
    "    'Criteres' : ['Temps Entrainement', 'Accuracy Entrainement', 'F1 Entrainement', 'Temps Test', 'Accuracy Test', 'F1 Test'],\n",
    "    'Entropie' : entropy_stats,\n",
    "    'Gini'     : gini_stats,\n",
    "    'XGBOOST'  : XGBOOST_stats\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Régression\n",
    "\n",
    "Dans cette seconde partie, nous allons entraîner un modèle de XGBOOST pour la régression et le comparer avec le modèle de régression linéaire en utilisant une dataset de Sklearn comportant les prix des maisons de California."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.1 Importer la dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16512, 8), (4128, 8))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "houses = fetch_california_housing()\n",
    "X, Y = houses.data, houses.target\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.2 Entraîner un modèle de régression linéaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.06410886247029467\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline      import make_pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "lineaire_stats = []\n",
    "\n",
    "reg_lineaire = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
    "\n",
    "temps_debut = timeit.default_timer()\n",
    "# Entraîner le modèle de régression linéaire\n",
    "reg_lineaire.fit(X_train, Y_train)\n",
    "lineaire_stats.append(timeit.default_timer() - temps_debut)\n",
    "\n",
    "temps_debut = timeit.default_timer()\n",
    "# Prédire\n",
    "Y_pred_lineaire = reg_lineaire.predict(X_test)\n",
    "lineaire_stats.append(timeit.default_timer() - temps_debut)\n",
    "\n",
    "# Calculer l'erreur quadratique moyenne (MSE)\n",
    "mse_lineaire = mean_squared_error(Y_test, Y_pred_lineaire)\n",
    "lineaire_stats.append(mse_lineaire)\n",
    "print(f\"MSE: {mse_lineaire}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.3 Entraîner un modèle XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.03559795217495412\n"
     ]
    }
   ],
   "source": [
    "# Définir les paramètres du modèle\n",
    "params = {\n",
    "    'objective': 'reg:squarederror',  # Fonction objective pour la régression\n",
    "    'max_depth': 3  # Profondeur maximale de l'arbre\n",
    "}\n",
    "\n",
    "XGBOOST_stats = []\n",
    "\n",
    "# Créer le modèle de régression XGBOOST avec les paramètres, changer la profondeur change le MSE, plus profond mieux c'est mais prend plus de temps\n",
    "reg_XGBOOST = xgb.XGBRegressor(**params)\n",
    "\n",
    "temps_debut = timeit.default_timer()\n",
    "# Entraîner le modèle\n",
    "reg_XGBOOST.fit(X_train, Y_train)\n",
    "XGBOOST_stats.append(timeit.default_timer() - temps_debut)\n",
    "\n",
    "temps_debut = timeit.default_timer()\n",
    "# Faire des prédictions sur l'ensemble de test\n",
    "Y_pred_XGBOOST = reg_XGBOOST.predict(X_test)\n",
    "XGBOOST_stats.append(timeit.default_timer() - temps_debut)\n",
    "\n",
    "# Calculer l'erreur quadratique moyenne (MSE)\n",
    "mse_XGBOOST = mean_squared_error(Y_test, Y_pred_XGBOOST)\n",
    "XGBOOST_stats.append(mse_XGBOOST)\n",
    "print(f\"MSE: {mse_XGBOOST}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Criteres</th>\n",
       "      <th>Linéaire</th>\n",
       "      <th>XGBOOST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Temps Entrainement</td>\n",
       "      <td>0.010386</td>\n",
       "      <td>0.213670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Temps Test</td>\n",
       "      <td>0.001254</td>\n",
       "      <td>0.001098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MSE</td>\n",
       "      <td>0.064109</td>\n",
       "      <td>0.035598</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Criteres  Linéaire   XGBOOST\n",
       "0  Temps Entrainement  0.010386  0.213670\n",
       "1          Temps Test  0.001254  0.001098\n",
       "2                 MSE  0.064109  0.035598"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\n",
    "    'Criteres' : ['Temps Entrainement','Temps Test', 'MSE'],\n",
    "    'Linéaire' : lineaire_stats,\n",
    "    'XGBOOST'  : XGBOOST_stats\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TP-yMQy8RZS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
